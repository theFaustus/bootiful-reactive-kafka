server:
  port: 8005

management:
  endpoints:
    web:
      exposure:
        include: "*"
  endpoint:
    health:
      show-details: always
  tracing:
    enabled: true
    sampling:
      probability: 1.0
    propagation:
      type: b3
  metrics:
    distribution:
      percentiles-histogram:
        http:
          server:
            requests: true
  health:
    livenessstate:
      enabled: true
    readinessstate:
      enabled: true

spring:
  profiles:
    active: test
  application:
    name: analytics-service
  data:
    r2dbc:
      repositories:
        enabled: true
  r2dbc:
    url: r2dbc:postgresql://localhost:5432/analytics
    username: admin
    password: 123456
  flyway:
    user: ${spring.r2dbc.username}
    password: ${spring.r2dbc.password}
    url: jdbc:postgresql://localhost:5432/analytics
    baseline-on-migrate: true
    repair-on-migrate: true
  netty:
    leak-detection: paranoid
  kafka:
    producers:
      DEFAULT:
        properties:
          bootstrap.servers: localhost:9092
          schema.registry.url: http://localhost:8081
          key.serializer: org.apache.kafka.common.serialization.StringSerializer
          value.serializer: org.apache.kafka.common.serialization.StringSerializer
      INIT_RESOURCES:
        topic: test-init-sandbox-resources
        properties:
          client.id: analytics.init-sandbox-resources
          retries: 3
          compression.type: snappy
      DESTROY_RESOURCES:
        topic: test-destroy-sandbox-resources
        properties:
          client.id: analytics.destroy-sandbox-resources
          compression.type: snappy
          value.serializer: org.springframework.kafka.support.serializer.JsonSerializer
    consumers:
      DEFAULT:
        properties:
          bootstrap.servers: localhost:9092
          schema.registry.url: localhost:8081
          auto.offset.reset: latest
          spring.json.use.type.headers: false
          key.deserializer: org.apache.kafka.common.serialization.StringDeserializer
          value.deserializer: org.apache.kafka.common.serialization.StringDeserializer
          spring.deserializer.key.delegate.class: org.apache.kafka.common.serialization.StringDeserializer
          spring.deserializer.value.delegate.class: org.apache.kafka.common.serialization.StringDeserializer
      SESSION-STATE-UPDATE:
        topic: test-session-state-update-events
        properties:
          client.id: analytics.session-state-update
          group.id: analytics.session-state-update.group
      LOGGED-IN-EVENT:
        topic: test-logged-in-events
        properties:
          client.id: analytics.logged-in-events
          group.id: analytics.logged-in-events.group
          value.deserializer: org.springframework.kafka.support.serializer.JsonDeserializer
          spring.json.value.default.type: "inc.evil.bootiful_reactive_kafka.messaging.kafka.consumer.log_event.model.LoggedInEvent"
      LOGGED-OUT-EVENT:
        topic: test-logged-out-events
        properties:
          client.id: analytics.logged-out-events
          group.id: analytics.logged-out-events.group
          value.deserializer: org.springframework.kafka.support.serializer.JsonDeserializer
          spring.json.value.default.type: "inc.evil.bootiful_reactive_kafka.messaging.kafka.consumer.log_event.model.LoggedOutEvent"
      SESSION_HACK_ATTEMPT:
        topic: test-session-hack-attempt-events
        properties:
          client.id: analytics.session-hack-attempt
          group.id: analytics.session-hack-attempt.group
          value.deserializer: io.confluent.kafka.streams.serdes.avro.SpecificAvroDeserializer

logging:
  level:
    inc.evil: DEBUG
    io.r2dbc.postgresql.QUERY: DEBUG # for queries
    io.r2dbc.postgresql.PARAM: DEBUG # for parameters
    org.zalando.logbook: trace
  pattern:
    level: "%5p [${spring.application.name:},%X{traceId:-},%X{spanId:-}]"
